{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "555e11b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe7e884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b450c088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f83af8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[\"text\",\"airline_sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "324e01b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0                @VirginAmerica What @dhepburn said.           neutral\n",
       "1  @VirginAmerica plus you've added commercials t...          positive\n",
       "2  @VirginAmerica I didn't today... Must mean I n...           neutral\n",
       "3  @VirginAmerica it's really aggressive to blast...          negative\n",
       "4  @VirginAmerica and it's a really big bad thing...          negative"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bc08b43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e5c9df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.airline_sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "581abbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                 0\n",
       "airline_sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d21a4935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.airline_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b2615233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c0d99a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df[\"airline_sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc685adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=sns.countplot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2d9c004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS=df.airline_sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ee0ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict={}\n",
    "for index,LABEL in enumerate(LABELS):\n",
    "    label_dict[LABEL]=index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6e1233ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 0, 'positive': 1, 'negative': 2}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "244fe2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"airline_sentiment\"]=df[\"airline_sentiment\"].map(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "172f8e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.index.values\n",
    "Y=df.airline_sentiment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "29a26ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aab21e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,Y_train,Y_val=train_test_split(X,Y,test_size=0.2,random_state=100,\n",
    "                                            stratify=df.airline_sentiment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d41bb8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11712,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "72a38c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2928,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a57ebd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"data_type\"]=[\"not_set\"]*df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "88b88828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>1</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>2</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>2</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  airline_sentiment  \\\n",
       "0                @VirginAmerica What @dhepburn said.                  0   \n",
       "1  @VirginAmerica plus you've added commercials t...                  1   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...                  0   \n",
       "3  @VirginAmerica it's really aggressive to blast...                  2   \n",
       "4  @VirginAmerica and it's a really big bad thing...                  2   \n",
       "\n",
       "  data_type  \n",
       "0   not_set  \n",
       "1   not_set  \n",
       "2   not_set  \n",
       "3   not_set  \n",
       "4   not_set  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cbdf1a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11740  5015 13952 ... 14507   426 11677]\n"
     ]
    }
   ],
   "source": [
    "df.loc[X_train,\"data_type\"]=\"train\"\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "adb514c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11488 12003  7586 ...  9410  5291  3717]\n"
     ]
    }
   ],
   "source": [
    "df.loc[X_val,\"data_type\"]=\"val\"\n",
    "print(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1f3a03be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>2479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>7343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>1835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text\n",
       "airline_sentiment data_type      \n",
       "0                 train      2479\n",
       "                  val         620\n",
       "1                 train      1890\n",
       "                  val         473\n",
       "2                 train      7343\n",
       "                  val        1835"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"airline_sentiment\",\"data_type\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1c127591",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.16) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29240a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "213e6206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length=df[\"text\"].str.len().max()\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2701bbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/joy/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoded_train_text=tokenizer.batch_encode_plus(df[df[\"data_type\"]==\"train\"].text.values,\n",
    "                                        max_length=200,\n",
    "                                        pad_to_max_length=True,\n",
    "                                        add_special_tokens=True,\n",
    "                                        return_attention_mask=True,\n",
    "                                        return_token_type_ids=True,\n",
    "                                        return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70e59c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41b951fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17798/350309463.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_input_ids=torch.tensor(encoded_train_text[\"input_ids\"])\n",
      "/tmp/ipykernel_17798/350309463.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_attention_mask=torch.tensor(encoded_train_text[\"attention_mask\"])\n"
     ]
    }
   ],
   "source": [
    "train_input_ids=torch.tensor(encoded_train_text[\"input_ids\"])\n",
    "train_attention_mask=torch.tensor(encoded_train_text[\"attention_mask\"])\n",
    "train_labels=torch.tensor(df[df[\"data_type\"]==\"train\"].airline_sentiment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6792180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11712, 200])\n",
      "torch.Size([11712, 200])\n",
      "torch.Size([11712])\n"
     ]
    }
   ],
   "source": [
    "print(train_input_ids.shape)\n",
    "print(train_attention_mask.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77efc6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joy/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoded_val_text=tokenizer.batch_encode_plus(df[df[\"data_type\"]==\"val\"].text.values,\n",
    "                                            max_length=200,\n",
    "                                            pad_to_max_length=True,\n",
    "                                            return_attention_mask=True,\n",
    "                                            add_special_tokens=True,\n",
    "                                            return_token_type_ids=True,\n",
    "                                            return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ee0a825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1030,  6261,  ...,     0,     0,     0],\n",
       "        [  101,  1030,  6261,  ...,     0,     0,     0],\n",
       "        [  101,  1030,  6261,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  4067,  2017,  ...,     0,     0,     0],\n",
       "        [  101,  1030, 25988,  ...,     0,     0,     0],\n",
       "        [  101,  1030, 25988,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_val_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5f77410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17798/1941009371.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_input_ids=torch.tensor(encoded_val_text[\"input_ids\"])\n",
      "/tmp/ipykernel_17798/1941009371.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_attention_mask=torch.tensor(encoded_val_text[\"attention_mask\"])\n"
     ]
    }
   ],
   "source": [
    "val_input_ids=torch.tensor(encoded_val_text[\"input_ids\"])\n",
    "val_attention_mask=torch.tensor(encoded_val_text[\"attention_mask\"])\n",
    "val_labels=torch.tensor(df[df[\"data_type\"]==\"val\"].airline_sentiment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "357f8ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2928, 200])\n",
      "torch.Size([2928, 200])\n",
      "torch.Size([2928])\n"
     ]
    }
   ],
   "source": [
    "print(val_input_ids.shape)\n",
    "print(val_attention_mask.shape)\n",
    "print(val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d464df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ea23f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_dataset=TensorDataset(train_input_ids,\n",
    "                           train_attention_mask,\n",
    "                           train_labels)\n",
    "\n",
    "Val_dataset=TensorDataset(val_input_ids,\n",
    "                         val_attention_mask,\n",
    "                         val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9485c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11712\n",
      "2928\n"
     ]
    }
   ],
   "source": [
    "print(len(Train_dataset))\n",
    "print(len(Val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fac0961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a48312e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(Train_dataset,\n",
    "                           batch_size=64,\n",
    "                           sampler=RandomSampler(Train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd827cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  101,  1030,  6261, 14074, 14735,  4283,  2000,  2115,  5151, 16392,\n",
       "          1011,  1046, 24316,  3626,  2040,  2333,  4020,  2000,  2131,  2033,\n",
       "          2188,  2000,  2624,  3799,  3892,   999,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4083fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader=DataLoader(Val_dataset,\n",
    "                       batch_size=64,\n",
    "                       sampler=RandomSampler(Val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "893f2342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DataLoader in module torch.utils.data.dataloader:\n",
      "\n",
      "class DataLoader(typing.Generic)\n",
      " |  DataLoader(*args, **kwds)\n",
      " |  \n",
      " |  Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
      " |  the given dataset.\n",
      " |  \n",
      " |  The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
      " |  iterable-style datasets with single- or multi-process loading, customizing\n",
      " |  loading order and optional automatic batching (collation) and memory pinning.\n",
      " |  \n",
      " |  See :py:mod:`torch.utils.data` documentation page for more details.\n",
      " |  \n",
      " |  Args:\n",
      " |      dataset (Dataset): dataset from which to load the data.\n",
      " |      batch_size (int, optional): how many samples per batch to load\n",
      " |          (default: ``1``).\n",
      " |      shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      " |          at every epoch (default: ``False``).\n",
      " |      sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
      " |          samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
      " |          implemented. If specified, :attr:`shuffle` must not be specified.\n",
      " |      batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
      " |          returns a batch of indices at a time. Mutually exclusive with\n",
      " |          :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
      " |          and :attr:`drop_last`.\n",
      " |      num_workers (int, optional): how many subprocesses to use for data\n",
      " |          loading. ``0`` means that the data will be loaded in the main process.\n",
      " |          (default: ``0``)\n",
      " |      collate_fn (Callable, optional): merges a list of samples to form a\n",
      " |          mini-batch of Tensor(s).  Used when using batched loading from a\n",
      " |          map-style dataset.\n",
      " |      pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
      " |          into device/CUDA pinned memory before returning them.  If your data elements\n",
      " |          are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
      " |          see the example below.\n",
      " |      drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      " |          if the dataset size is not divisible by the batch size. If ``False`` and\n",
      " |          the size of dataset is not divisible by the batch size, then the last batch\n",
      " |          will be smaller. (default: ``False``)\n",
      " |      timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      " |          from workers. Should always be non-negative. (default: ``0``)\n",
      " |      worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
      " |          worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      " |          input, after seeding and before data loading. (default: ``None``)\n",
      " |      multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n",
      " |          ``None``, the default `multiprocessing context`_ of your operating system will\n",
      " |          be used. (default: ``None``)\n",
      " |      generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
      " |          by RandomSampler to generate random indexes and multiprocessing to generate\n",
      " |          ``base_seed`` for workers. (default: ``None``)\n",
      " |      prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
      " |          in advance by each worker. ``2`` means there will be a total of\n",
      " |          2 * num_workers batches prefetched across all workers. (default value depends\n",
      " |          on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
      " |          Otherwise, if value of ``num_workers > 0`` default is ``2``).\n",
      " |      persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n",
      " |          the worker processes after a dataset has been consumed once. This allows to\n",
      " |          maintain the workers `Dataset` instances alive. (default: ``False``)\n",
      " |      pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is\n",
      " |          ``True``.\n",
      " |  \n",
      " |  \n",
      " |  .. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
      " |               cannot be an unpicklable object, e.g., a lambda function. See\n",
      " |               :ref:`multiprocessing-best-practices` on more details related\n",
      " |               to multiprocessing in PyTorch.\n",
      " |  \n",
      " |  .. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
      " |               When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
      " |               it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
      " |               rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
      " |               configurations. This represents the best guess PyTorch can make because PyTorch\n",
      " |               trusts user :attr:`dataset` code in correctly handling multi-process\n",
      " |               loading to avoid duplicate data.\n",
      " |  \n",
      " |               However, if sharding results in multiple workers having incomplete last batches,\n",
      " |               this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
      " |               be broken into multiple ones and (2) more than one batch worth of samples can be\n",
      " |               dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
      " |               cases in general.\n",
      " |  \n",
      " |               See `Dataset Types`_ for more details on these two types of datasets and how\n",
      " |               :class:`~torch.utils.data.IterableDataset` interacts with\n",
      " |               `Multi-process data loading`_.\n",
      " |  \n",
      " |  .. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
      " |               :ref:`data-loading-randomness` notes for random seed related questions.\n",
      " |  \n",
      " |  .. _multiprocessing context:\n",
      " |      https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataLoader\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, dataset: torch.utils.data.dataset.Dataset[+T_co], batch_size: Union[int, NoneType] = 1, shuffle: Union[bool, NoneType] = None, sampler: Union[torch.utils.data.sampler.Sampler, Iterable, NoneType] = None, batch_sampler: Union[torch.utils.data.sampler.Sampler[List], Iterable[List], NoneType] = None, num_workers: int = 0, collate_fn: Union[Callable[[List[~T]], Any], NoneType] = None, pin_memory: bool = False, drop_last: bool = False, timeout: float = 0, worker_init_fn: Union[Callable[[int], NoneType], NoneType] = None, multiprocessing_context=None, generator=None, *, prefetch_factor: Union[int, NoneType] = None, persistent_workers: bool = False, pin_memory_device: str = '')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self) -> '_BaseDataLoaderIter'\n",
      " |      # We quote '_BaseDataLoaderIter' since it isn't defined yet and the definition can't be moved up\n",
      " |      # since '_BaseDataLoaderIter' references 'DataLoader'.\n",
      " |  \n",
      " |  __len__(self) -> int\n",
      " |  \n",
      " |  __setattr__(self, attr, val)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  check_worker_number_rationality(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  multiprocessing_context\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_iterator': typing.Union[ForwardRef('_BaseDataLoad...\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |  \n",
      " |  __parameters__ = (+T_co,)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwds)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56bfbe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d7f8f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_name=BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73250ae8",
   "metadata": {},
   "source": [
    "# Customized model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3431970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e053f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment_analysis_model(nn.Module):\n",
    "    def __init__(self,pretrained_model_name,input_size,hidden_size,output_size):\n",
    "        super(sentiment_analysis_model,self).__init__()\n",
    "        #BERT model first layer\n",
    "        self.bert_model= BertForSequenceClassification.from_pretrained(pretrained_model_name)\n",
    "        \n",
    "        #Additional Layers\n",
    "        self.dropout=nn.Dropout(0.1)\n",
    "        self.fc1=nn.Linear(input_size,hidden_size)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.fc2=nn.Linear(hidden_size,output_size)\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self,input_ids,attention_mask):\n",
    "        #BERT forward pass\n",
    "        outputs=self.bert_model(input_ids,attention_mask)\n",
    "        \n",
    "        #extract logits from bert output\n",
    "        bert_logits=outputs.logits\n",
    "        \n",
    "        #Additional layers\n",
    "        x=self.dropout(bert_logits)\n",
    "        x=self.fc1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fc2(x)\n",
    "        x=self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "input_size=256\n",
    "hidden_size=64\n",
    "output_size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff2ef04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "Model=sentiment_analysis_model(pretrained_model_name=\"bert-base-uncased\",\n",
    "                               input_size=input_size,\n",
    "                               hidden_size=hidden_size,\n",
    "                               output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "89abc96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17064708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 16:29:57.191484: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-23 16:29:57.289907: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-23 16:29:59.505753: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#optimizer\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "559de70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joy/.local/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer=AdamW(Model.parameters(),\n",
    "               lr=1e-6,\n",
    "               eps=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1539efb",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "967fe4f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mModel\u001b[49m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs,attention_mask,labels \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m      5\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Model' is not defined"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "for epoch in range(epochs):\n",
    "    Model.train()\n",
    "    for inputs,attention_mask,labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs=Model(inputs,attention_mask)\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "    \n",
    "\n",
    "    Model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss=0.0\n",
    "        correct=0\n",
    "        total=0\n",
    "        \n",
    "        for val_inputs,val_labels in val_dataloader:\n",
    "            val_outputs=Model(val_inputs)\n",
    "            val_losses=criterion(val_outputs,val_labels)\n",
    "            val_loss+=val_loss.item()\n",
    "            \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}, Val Loss: {val_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c8fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(name,age):\n",
    "    person=name+\" \"+age\n",
    "    return person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fa7f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=func(\"Joy\",\"28\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad1ace46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joy 28\n"
     ]
    }
   ],
   "source": [
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67754e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number is Even\n"
     ]
    }
   ],
   "source": [
    "def func2(number):\n",
    "    if number%2==0:\n",
    "        print(\"The number is Even\")\n",
    "    else:\n",
    "        print(\"The number is odd\")\n",
    "        \n",
    "ob=func2(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "317558a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func3(num):\n",
    "    if num<18:\n",
    "        print(\"Under 18.\")\n",
    "    else:\n",
    "        print(\"Adult Person.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a3904da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adult Person.\n"
     ]
    }
   ],
   "source": [
    "ob3=func3(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39a9ce58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225\n"
     ]
    }
   ],
   "source": [
    "sum=0\n",
    "for i in range (1,50):\n",
    "    sum+=i\n",
    "    \n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bea773c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n"
     ]
    }
   ],
   "source": [
    "def func4(n):\n",
    "    sum=0\n",
    "    for i in range(n):\n",
    "        sum+=i \n",
    "    return sum\n",
    "\n",
    "ob4=func4(20)\n",
    "print(ob4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4005fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n",
      "435\n"
     ]
    }
   ],
   "source": [
    "def func4(n):\n",
    "    sum = 0\n",
    "    for i in range(n):\n",
    "        \n",
    "        sum += i\n",
    "    return sum\n",
    "\n",
    "ob4 = func4(20)\n",
    "ob5=func4(30)\n",
    "print(ob4)\n",
    "print(ob5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9f41dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class name_class:\n",
    "    def name_func(name):\n",
    "        name=\"Joy\"\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a85d9a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joy\n"
     ]
    }
   ],
   "source": [
    "class_obj=name_class()\n",
    "print(class_obj.name_func())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4dfccf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.name_class object at 0x7f92fc4689d0>\n"
     ]
    }
   ],
   "source": [
    "print(class_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8279ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class par:\n",
    "    def __init__(self,age):\n",
    "        self.age=age\n",
    "        func3(self.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0ea227d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under 18.\n"
     ]
    }
   ],
   "source": [
    "o=par(age=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ed8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
