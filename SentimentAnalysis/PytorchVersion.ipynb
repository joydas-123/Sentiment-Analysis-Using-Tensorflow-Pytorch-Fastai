{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8edea16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26175d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"smile-annotations-final.csv\",names=[\"id\",\"text\",\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "342901c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>611857364396965889</td>\n",
       "      <td>@aandraous @britishmuseum @AndrewsAntonio Merc...</td>\n",
       "      <td>nocode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>614484565059596288</td>\n",
       "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>614746522043973632</td>\n",
       "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>614877582664835073</td>\n",
       "      <td>@Sofabsports thank you for following me back. ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>611932373039644672</td>\n",
       "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  611857364396965889  @aandraous @britishmuseum @AndrewsAntonio Merc...   \n",
       "1  614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...   \n",
       "2  614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...   \n",
       "3  614877582664835073  @Sofabsports thank you for following me back. ...   \n",
       "4  611932373039644672  @britishmuseum @TudorHistory What a beautiful ...   \n",
       "\n",
       "  category  \n",
       "0   nocode  \n",
       "1    happy  \n",
       "2    happy  \n",
       "3    happy  \n",
       "4    happy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e5ba659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "nocode               1572\n",
       "happy                1137\n",
       "not-relevant          214\n",
       "angry                  57\n",
       "surprise               35\n",
       "sad                    32\n",
       "happy|surprise         11\n",
       "happy|sad               9\n",
       "disgust|angry           7\n",
       "disgust                 6\n",
       "sad|disgust             2\n",
       "sad|angry               2\n",
       "sad|disgust|angry       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25ef2fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[\"text\",\"category\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ba8d541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@aandraous @britishmuseum @AndrewsAntonio Merc...</td>\n",
       "      <td>nocode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Sofabsports thank you for following me back. ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text category\n",
       "0  @aandraous @britishmuseum @AndrewsAntonio Merc...   nocode\n",
       "1  Dorian Gray with Rainbow Scarf #LoveWins (from...    happy\n",
       "2  @SelectShowcase @Tate_StIves ... Replace with ...    happy\n",
       "3  @Sofabsports thank you for following me back. ...    happy\n",
       "4  @britishmuseum @TudorHistory What a beautiful ...    happy"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64bde33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "nocode               1572\n",
       "happy                1137\n",
       "not-relevant          214\n",
       "angry                  57\n",
       "surprise               35\n",
       "sad                    32\n",
       "happy|surprise         11\n",
       "happy|sad               9\n",
       "disgust|angry           7\n",
       "disgust                 6\n",
       "sad|disgust             2\n",
       "sad|angry               2\n",
       "sad|disgust|angry       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36d83c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text        0\n",
       "category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93326604",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_categories=['happy', 'not-relevant', 'angry', 'surprise', 'sad', 'disgust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f515902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"category\"].isin(selected_categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef185c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "happy           1137\n",
       "not-relevant     214\n",
       "angry             57\n",
       "surprise          35\n",
       "sad               32\n",
       "disgust            6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02181b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Sofabsports thank you for following me back. ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lucky @FitzMuseum_UK! Good luck @MirandaStearn...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Yr 9 art students are off to the @britishmuseu...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@RAMMuseum Please vote for us as @sainsbury #s...</td>\n",
       "      <td>not-relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>#AskTheGallery Have you got plans to privatise...</td>\n",
       "      <td>not-relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@BarbyWT @britishmuseum so beautiful</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text      category\n",
       "1   Dorian Gray with Rainbow Scarf #LoveWins (from...         happy\n",
       "2   @SelectShowcase @Tate_StIves ... Replace with ...         happy\n",
       "3   @Sofabsports thank you for following me back. ...         happy\n",
       "4   @britishmuseum @TudorHistory What a beautiful ...         happy\n",
       "5   @NationalGallery @ThePoldarkian I have always ...         happy\n",
       "9   Lucky @FitzMuseum_UK! Good luck @MirandaStearn...         happy\n",
       "12  Yr 9 art students are off to the @britishmuseu...         happy\n",
       "15  @RAMMuseum Please vote for us as @sainsbury #s...  not-relevant\n",
       "16  #AskTheGallery Have you got plans to privatise...  not-relevant\n",
       "18               @BarbyWT @britishmuseum so beautiful         happy"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51d78692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "happy           1137\n",
       "not-relevant     214\n",
       "angry             57\n",
       "surprise          35\n",
       "sad               32\n",
       "disgust            6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0acf3d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels = df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5801f695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['happy', 'not-relevant', 'angry', 'disgust', 'sad', 'surprise'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3634e42",
   "metadata": {},
   "source": [
    "# This is used to convert categorical value to numerical values. Alternatives of LabelEncoder, OneHotEncoding etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e56bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398f7b10",
   "metadata": {},
   "source": [
    "###### The enumerate function is used to iterate over the (possible_labels) list along with its index. It returns pairs of index and corresponding values. For each pair (index, possible_label), the code assigns the label (possible_label) as the key in the dictionary (label_dict), and the index (index) as the corresponding value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab579930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'happy': 0,\n",
       " 'not-relevant': 1,\n",
       " 'angry': 2,\n",
       " 'disgust': 3,\n",
       " 'sad': 4,\n",
       " 'surprise': 5}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1079f5d",
   "metadata": {},
   "source": [
    "###### map() function replaces the values in the 'category' column with the corresponding values from a dictionary (label_dict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b75bd213",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.category = df['category'].map(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "721135d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Sofabsports thank you for following me back. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category\n",
       "1  Dorian Gray with Rainbow Scarf #LoveWins (from...         0\n",
       "2  @SelectShowcase @Tate_StIves ... Replace with ...         0\n",
       "3  @Sofabsports thank you for following me back. ...         0\n",
       "4  @britishmuseum @TudorHistory What a beautiful ...         0\n",
       "5  @NationalGallery @ThePoldarkian I have always ...         0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77eddc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.index.values\n",
    "Y=df[\"category\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "929b3952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(df.index.isin(X).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "447063eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2c321a",
   "metadata": {},
   "source": [
    "###### The stratify parameter in the train_test_split function is used to ensure that the distribution of the target variable (in this case, the 'category' column) is preserved in both the training and validation sets. This is particularly important when dealing with imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c421ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X,Y,test_size=0.15,random_state=42,\n",
    "                                                  stratify=df.category.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5bfe262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258,)\n",
      "(1258,)\n",
      "(223,)\n",
      "(223,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfc00a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(df.index.isin(X_train).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c58d675b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([   1,    2,    3,    4,    5,    9,   12,   15,   16,   18,\n",
      "       ...\n",
      "       3068, 3070, 3071, 3076, 3077, 3078, 3079, 3080, 3082, 3083],\n",
      "      dtype='int64', length=1481)\n"
     ]
    }
   ],
   "source": [
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef76516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data_type'] = ['not_set']*df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e43fd49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2934 2882 1791 ...  632 1311 2844]\n"
     ]
    }
   ],
   "source": [
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3410eabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2875 1843 1928 1372  436  322 1954 2349 2671 1676   98  152 2902  366\n",
      "   33 1489 2150 1379 1668 2333  889 1426 1907 2136 1702 2115  592 2727\n",
      " 3054 1277   36  250 2751  650  556 1809  937 3076 1591  523  978 1296\n",
      " 2993 1865 3019  357 1507 1628   92 2381  832 2929 1014 1990  672  743\n",
      "  866  999 2071  445 1560 3021 1252 1998  486 1720  226  872 2701 1328\n",
      "  883 1714  657 3051 1332  175 3068 3064 1066 1667 1032 1696  574 2842\n",
      " 1001 1636  462 1250 2431  647  942 2785 2140 1453 1517  980 1812 2799\n",
      " 1996 2796 2722  527 1943 2127 1336 2781 2199 1020   52 2724 1015 1853\n",
      " 3070  696 2610  239  734 1475 1818 1596  495  624 1845 3014  988 1007\n",
      " 1980 1772 1174   69  103 2805 1208 1483 2551  114  753 1045  255  589\n",
      "  826 1923 2052 2152  245  676 2619 2078  262  579 1212 1254  500 1480\n",
      " 2170 1079 3020 2353 2087  497 2343 2267 1621 1844  345 2822 2681 1318\n",
      " 2254  533 1656 1401 2274 2779 2363  772   15 1387  899 2605   55  368\n",
      " 1452 1472 1196 1476 2684 2118 2133 1762 1924 2454  913  621  230 1807\n",
      " 2450 1802 1102 2845 2040  836 1963 2628 2312 1405 1231  538 1718 2044\n",
      "  724  418 1710 2319 2952 1739 2190 2546 1084 2787 1366  425 2777]\n"
     ]
    }
   ],
   "source": [
    "df.loc[X_val, 'data_type'] = 'val'\n",
    "print(X_val)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e6cade4",
   "metadata": {},
   "source": [
    "df.loc[df.index.isin(X_train), 'data_type'] = 'train'\n",
    "df.loc[df.index.isin(X_val), 'data_type'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6e7203a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Sofabsports thank you for following me back. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category data_type\n",
       "1  Dorian Gray with Rainbow Scarf #LoveWins (from...         0     train\n",
       "2  @SelectShowcase @Tate_StIves ... Replace with ...         0     train\n",
       "3  @Sofabsports thank you for following me back. ...         0     train\n",
       "4  @britishmuseum @TudorHistory What a beautiful ...         0     train\n",
       "5  @NationalGallery @ThePoldarkian I have always ...         0     train"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ba4cb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>train</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>train</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>train</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text\n",
       "category data_type      \n",
       "0        train       966\n",
       "         val         171\n",
       "1        train       182\n",
       "         val          32\n",
       "2        train        48\n",
       "         val           9\n",
       "3        train         5\n",
       "         val           1\n",
       "4        train        27\n",
       "         val           5\n",
       "5        train        30\n",
       "         val           5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['category', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a328e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Sofabsports thank you for following me back. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078</th>\n",
       "      <td>@_TheWhitechapel @Campaignforwool @SlowTextile...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>“@britishmuseum: Thanks for ranking us #1 in @...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080</th>\n",
       "      <td>MT @AliHaggett: Looking forward to our public ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082</th>\n",
       "      <td>@MrStuchbery @britishmuseum Mesmerising.</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>@NationalGallery The 2nd GENOCIDE against #Bia...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1481 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  category data_type\n",
       "1     Dorian Gray with Rainbow Scarf #LoveWins (from...         0     train\n",
       "2     @SelectShowcase @Tate_StIves ... Replace with ...         0     train\n",
       "3     @Sofabsports thank you for following me back. ...         0     train\n",
       "4     @britishmuseum @TudorHistory What a beautiful ...         0     train\n",
       "5     @NationalGallery @ThePoldarkian I have always ...         0     train\n",
       "...                                                 ...       ...       ...\n",
       "3078  @_TheWhitechapel @Campaignforwool @SlowTextile...         1     train\n",
       "3079  “@britishmuseum: Thanks for ranking us #1 in @...         0     train\n",
       "3080  MT @AliHaggett: Looking forward to our public ...         0     train\n",
       "3082           @MrStuchbery @britishmuseum Mesmerising.         0     train\n",
       "3083  @NationalGallery The 2nd GENOCIDE against #Bia...         1     train\n",
       "\n",
       "[1481 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4f3e9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.16) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0ace8c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "###### \"TensorDataset\" is a PyTorch dataset wrapper that allows you to create a dataset from a list of tensors. It's commonly used for creating datasets for training and validation in PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88100690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3503ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "11c7c9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e9e3033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame based on the condition\n",
    "train_texts = df[df[\"data_type\"] == 'train'].text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7126c6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1258"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b4d831",
   "metadata": {},
   "source": [
    "# Preparing Training and Validation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee759f3",
   "metadata": {},
   "source": [
    "###### Prepare training , validation data  --> convert reviews into tokens --> convert tokens into token ids --> set max len --> creating padding --> all this will done by tokenizer.encode_plus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06028e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/joy/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoded_train_data=tokenizer.batch_encode_plus(train_texts,\n",
    "                                              add_special_tokens=True,\n",
    "                                              return_attention_mask=True,\n",
    "                                              pad_to_max_length=True,\n",
    "                                              max_length=256,\n",
    "                                              return_tensors=\"pt\"\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64a97b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101, 16092,  3897,  ...,     0,     0,     0],\n",
      "        [  101,  1030, 27034,  ...,     0,     0,     0],\n",
      "        [  101,  1030, 10682,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11047,  1030,  ...,     0,     0,     0],\n",
      "        [  101,  1030,  3680,  ...,     0,     0,     0],\n",
      "        [  101,  1030,  2120,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "print(encoded_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ad067d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_val_data=tokenizer.batch_encode_plus(df[df[\"data_type\"]==\"val\"].text.values,\n",
    "                                            add_special_tokens=True,\n",
    "                                            return_attention_mask=True,\n",
    "                                            pad_to_max_length=True,\n",
    "                                            max_length=256,\n",
    "                                            return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "850692e3",
   "metadata": {},
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "texts = [\"Hello, how are you?\", \"Transformers are awesome!\"]\n",
    "encoded_data = tokenizer.batch_encode_plus(\n",
    "    texts,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=16,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "print(encoded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39ed201b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21299/1912464806.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_train_ids=torch.tensor(encoded_train_data[\"input_ids\"])\n",
      "/tmp/ipykernel_21299/1912464806.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_attention_mask=torch.tensor(encoded_train_data[\"attention_mask\"])\n"
     ]
    }
   ],
   "source": [
    "input_train_ids=torch.tensor(encoded_train_data[\"input_ids\"])\n",
    "train_attention_mask=torch.tensor(encoded_train_data[\"attention_mask\"])\n",
    "train_labels=torch.tensor(df[df.data_type==\"train\"].category.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1abb5050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 16092,  3897,  ...,     0,     0,     0],\n",
      "        [  101,  1030, 27034,  ...,     0,     0,     0],\n",
      "        [  101,  1030, 10682,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 11047,  1030,  ...,     0,     0,     0],\n",
      "        [  101,  1030,  3680,  ...,     0,     0,     0],\n",
      "        [  101,  1030,  2120,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "print(input_train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6ced39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(train_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f007f7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21299/109597183.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_val_ids=torch.tensor(encoded_val_data[\"input_ids\"])\n",
      "/tmp/ipykernel_21299/109597183.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_attention_mask=torch.tensor(encoded_val_data[\"attention_mask\"])\n"
     ]
    }
   ],
   "source": [
    "input_val_ids=torch.tensor(encoded_val_data[\"input_ids\"])\n",
    "val_attention_mask=torch.tensor(encoded_val_data[\"attention_mask\"])\n",
    "val_labels=torch.tensor(df[df.data_type==\"val\"].category.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d81fc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1258, 256])\n",
      "torch.Size([1258, 256])\n",
      "torch.Size([1258])\n"
     ]
    }
   ],
   "source": [
    "print(input_train_ids.shape)\n",
    "print(train_attention_mask.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1a5ec26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([223, 256])\n",
      "torch.Size([223, 256])\n",
      "torch.Size([223])\n"
     ]
    }
   ],
   "source": [
    "print(input_val_ids.shape)\n",
    "print(val_attention_mask.shape)\n",
    "print(val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "714e9806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 4, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 4, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 0, 4, 0, 2, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 2, 1, 1, 0, 3, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        5, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 4, 0, 0, 1, 0, 0, 0, 0, 0, 2, 1,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0,\n",
      "        5, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf8e27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=TensorDataset(input_train_ids,\n",
    "                            train_attention_mask,\n",
    "                            train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4e49017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset=TensorDataset(input_val_ids,\n",
    "                          val_attention_mask,\n",
    "                          val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "afd2498f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258\n",
      "223\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53751694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101, 16092,  3897,  ...,     0,     0,     0],\n",
       "         [  101,  1030, 27034,  ...,     0,     0,     0],\n",
       "         [  101,  1030, 10682,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101, 11047,  1030,  ...,     0,     0,     0],\n",
       "         [  101,  1030,  3680,  ...,     0,     0,     0],\n",
       "         [  101,  1030,  2120,  ...,     0,     0,     0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([0, 0, 0,  ..., 0, 0, 1]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a185cc66",
   "metadata": {},
   "source": [
    "# Setting BERT Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed8acf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fdfda8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "Model=BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476eef04",
   "metadata": {},
   "source": [
    "# Creating Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ec6de14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a79ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloaders=DataLoader(train_dataset,\n",
    "                            batch_size=64,\n",
    "                            sampler=RandomSampler(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae3614b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloaders=DataLoader(val_dataset,\n",
    "                          batch_size=32,\n",
    "                          sampler=RandomSampler(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c5e38c",
   "metadata": {},
   "source": [
    "# Setting Up Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b233073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 22:55:32.092581: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-20 22:55:32.694849: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-20 22:55:33.892837: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW,get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8932d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joy/.local/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer=AdamW(Model.parameters(),\n",
    "               lr=1e-5,\n",
    "               eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a03843c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "scheduler=get_linear_schedule_with_warmup(optimizer,\n",
    "                                         num_warmup_steps=0,\n",
    "                                         num_training_steps=len(train_dataloaders)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "de1bd870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8cce43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds,labels):\n",
    "    preds_flat=np.argmax(preds,axis=1).flatten()\n",
    "    labels_flat=labels.flatten()\n",
    "    return f1_score_func(labels_flat,preds_flat,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "081ea029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds,labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a8bd0e",
   "metadata": {},
   "source": [
    "# Creating Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8c921d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "20b0ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val=100\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "471d9ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "Model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "ad35decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val_dataloaders):\n",
    "\n",
    "    Model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in tqdm(val_dataloaders):\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(val_dataloaders) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "a292b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55df41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ff0da8563943c1a8eaef3965490422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73648f062334825b6d4bceaf12eb34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    Model.train()\n",
    "    loss_train_total = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_dataloaders, \n",
    "                        desc='Epoch {:1d}'.format(epoch), \n",
    "                        leave=False, \n",
    "                        disable=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        Model.zero_grad()\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2]\n",
    "        }\n",
    "        \n",
    "        outputs = Model(**inputs)\n",
    "        loss = outputs[0]\n",
    "        loss_train_total +=loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(Model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
    "    \n",
    "    #torch.save(model.state_dict(), f'Models/BERT_ft_Epoch{epoch}.model')\n",
    "    \n",
    "    tqdm.write('\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(train_dataloaders)\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(val_dataloaders)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec4da7f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_per_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maccuracy_per_class\u001b[49m(predictions, true_vals)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_per_class' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc1679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(get_linear_schedule_with_warmup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f08f5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ddb5df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
